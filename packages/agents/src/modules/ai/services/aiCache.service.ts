import { createHash } from 'crypto';
import { DatabaseClient } from './analyticsEvent.service'; // Re-using placeholder DB client type

// Define a more specific structure for what's stored/retrieved from cache related to AI
interface AICacheRecord {
  id?: string; // UUID, primary key
  content_hash: string;
  prompt_representation: string; // Normalized/sanitized prompt or key elements
  generated_content: string;
  content_type: string; // e.g., 'resume_summary_generation', 'experience_bullet_improvement'
  ai_model_used?: string;
  created_at?: Date;
  last_accessed_at?: Date;
  access_count?: number;
}

export class AICacheService {
  private db: DatabaseClient;

  constructor(db: DatabaseClient) {
    this.db = db;
  }

  /**
   * Generates a SHA256 hash for a given string input.
   * Used to create a consistent content_hash for prompts.
   * @param input - The string to hash (e.g., normalized prompt).
   * @returns A SHA256 hash string.
   */
  private generateContentHash(input: string): string {
    return createHash('sha256').update(input).digest('hex');
  }

  /**
   * Normalizes a prompt or its key elements for consistent hashing.
   * This is a simplified example. Real normalization might involve:
   * - Lowercasing
   * - Removing excessive whitespace
   - Sorting keywords if their order doesn't matter
   * - Standardizing certain phrases
   * @param promptElements - Key elements that define the AI request uniquely.
   * @returns A normalized string representation.
   */
  private normalizePromptForHashing(promptElements: Record<string, any>): string {
    // Simple example: sort keys and join key-value pairs
    // More sophisticated normalization would be needed for robust caching.
    const sortedKeys = Object.keys(promptElements).sort();
    const normalizedString = sortedKeys.map(key => `${key}:${String(promptElements[key]).trim().toLowerCase()}`).join('|');
    return normalizedString;
  }

  /**
   * Retrieves a cached AI response from the database.
   * @param promptKeyElements - An object with key elements of the prompt to generate the hash.
   * @returns The cached generated_content if found, otherwise null.
   */
  async getCachedResponse(promptKeyElements: Record<string, any>): Promise<string | null> {
    const normalizedPrompt = this.normalizePromptForHashing(promptKeyElements);
    const contentHash = this.generateContentHash(normalizedPrompt);

    console.log(`AICacheService: Checking cache for hash ${contentHash} (from prompt elements: ${JSON.stringify(promptKeyElements)})`);

    // Pseudo-code for database query
    // const result = await this.db.queryRaw(
    //   "SELECT generated_content, id, access_count FROM ai_content_cache WHERE content_hash = $1 LIMIT 1",
    //   [contentHash]
    // );
    // Simulating DB call
    const mockResults: AICacheRecord[] = (this.db as any)._mockGetAICacheByHash?.(contentHash) || [];


    if (mockResults && mockResults.length > 0) {
      const record = mockResults[0];
      console.log(`AICacheService: Cache hit for hash ${contentHash}.`);
      // Update last_accessed_at and access_count (pseudo-code)
      // await this.db.queryRaw(
      //  "UPDATE ai_content_cache SET last_accessed_at = NOW(), access_count = $1 WHERE id = $2",
      //  [(record.access_count || 0) + 1, record.id]
      // );
      (this.db as any)._mockUpdateAICacheAccess?.(record.id, (record.access_count || 0) + 1);
      return record.generated_content;
    }

    console.log(`AICacheService: Cache miss for hash ${contentHash}.`);
    return null;
  }

  /**
   * Stores an AI response in the cache.
   * @param promptKeyElements - An object with key elements of the prompt.
   * @param originalPrompt - The full original prompt or its representation.
   * @param generatedContent - The content generated by the AI.
   * @param contentType - The type/category of the content.
   * @param aiModelUsed - The AI model that generated the content.
   */
  async setCachedResponse(
    promptKeyElements: Record<string, any>,
    originalPrompt: string,
    generatedContent: string,
    contentType: string,
    aiModelUsed?: string
  ): Promise<void> {
    const normalizedPrompt = this.normalizePromptForHashing(promptKeyElements);
    const contentHash = this.generateContentHash(normalizedPrompt);

    const newRecord: AICacheRecord = {
      content_hash: contentHash,
      prompt_representation: originalPrompt, // Or the normalizedPrompt if preferred for storage
      generated_content: generatedContent,
      content_type: contentType,
      ai_model_used: aiModelUsed,
      created_at: new Date(),
      last_accessed_at: new Date(),
      access_count: 1,
    };

    console.log(`AICacheService: Setting cache for hash ${contentHash} (from prompt elements: ${JSON.stringify(promptKeyElements)})`);

    // Pseudo-code for database insertion
    // await this.db.insert('ai_content_cache', newRecord);
    // Simulating DB call
    (this.db as any)._mockInsertAICache?.(newRecord);


    console.log(`AICacheService: Stored response for hash ${contentHash} in cache.`);
  }
}

// Example Usage (conceptual)
/*
const mockDbClientWithCache: DatabaseClient & { _cache: AICacheRecord[], _mockGetAICacheByHash?: any, _mockUpdateAICacheAccess?: any, _mockInsertAICache?: any } = {
  _cache: [],
  insert: async (tableName, data) => { console.log(`Mock DB Insert into ${tableName}:`, data); },
  queryRaw: async (sql, params) => { console.log(`Mock DB QueryRaw: ${sql}`, params); return []; },

  _mockGetAICacheByHash(hash: string) {
    return this._cache.filter(r => r.content_hash === hash);
  },
  _mockUpdateAICacheAccess(id: string | undefined, count: number) {
    const record = this._cache.find(r => r.id === id);
    if (record) {
        record.last_accessed_at = new Date();
        record.access_count = count;
        console.log("Mock DB: Updated access for cache ID", id);
    }
  },
  _mockInsertAICache(record: AICacheRecord) {
    record.id = crypto.randomUUID(); // Simulate DB generating ID
    this._cache.push(record);
    console.log("Mock DB: Inserted into AI Cache", record);
  }
};

const cacheService = new AICacheService(mockDbClientWithCache);

async function testCache() {
  const promptKeyElements1 = { sectionType: "summary", jobTitle: "Engineer", skills: "React,Node" };
  const originalPrompt1 = "Generate summary for Engineer with React,Node skills.";
  const model1 = "gpt-4";

  let content1 = await cacheService.getCachedResponse(promptKeyElements1);
  if (!content1) {
    content1 = "This is a generated summary for Engineer.";
    await cacheService.setCachedResponse(promptKeyElements1, originalPrompt1, content1, "summary_generation", model1);
  }
  console.log("Content 1:", content1);

  let content2 = await cacheService.getCachedResponse(promptKeyElements1); // Should be a cache hit
  console.log("Content 2 (from cache):", content2);

  console.log("Current Cache State:", mockDbClientWithCache._cache);
}

testCache();
*/

console.log("AICacheService.ts created in packages/agents/src/modules/ai/services/");
